<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models">
  <meta name="keywords" content="PHYBench, Large Language Models, Physical Perception, Physical Reasoning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <!-- MathJax -->
<script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start navbar-centered">
        <a title="home" ="navbar-item" href="https://stephenqsstarthomas.github.io">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item">
              Coming Soon
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://stephenqsstarthomas.github.io">Shi Qiu</a><sup>1</sup>,</span>
                <span class="author-block">Shaoyang Guo<sup>1</sup>,</span>
                <span class="author-block"><a href="https://github.com/SonnyNondegeneracy">Zhuo-Yang Song</a> <sup>1</sup>,</span>
                <span class="author-block"><a href="https://renko6626.github.io">Yunbo Sun</a><sup>1</sup>,</span>
                <span class="author-block"><a href="https://github.com/parkcai">Zeyu Cai</a><sup>1</sup>,</span>
                <span class="author-block"><a href="https://github.com/wjsoj">Jiashen Wei</a><sup>1</sup>,</span>
                <span class="author-block"><a href="https://github.com/Dennisbroo">Tianyu Luo</a><sup>1</sup>,</span>
                <span class="author-block">Yixuan Yin<sup>1</sup>,</span>
                <span class="author-block">Haoxu Zhang<sup>1</sup>,</span>
                <span class="author-block"><a href="https://aheadofpotato.github.io">Yi Hu</a><sup>2</sup>,</span>
                <span class="author-block">Chenyang Wang<sup>1</sup>,</span>
                <span class="author-block">Chencheng Tang<sup>1</sup>,</span>
                <span class="author-block">Haoling Chang<sup>1</sup>,</span>
                <span class="author-block">Qi Liu<sup>1</sup>,</span>
                <span class="author-block">Ziheng Zhou<sup>1</sup>,</span>
                <span class="author-block">Tianyu Zhang<sup>1</sup>,</span>
                <span class="author-block">Jingtian Zhang<sup>1</sup>,</span>
                <span class="author-block">Zhangyi Liu<sup>1</sup>,</span>
                <span class="author-block">Minghao Li<sup>1</sup>,</span>
                <span class="author-block">Yuku Zhang<sup>1</sup>,</span>
                <span class="author-block">Boxuan Jing<sup>1</sup>,</span>
                <span class="author-block">Xianqi Yin<sup>1</sup>,</span>
                <span class="author-block">Yutong Ren<sup>1</sup>,</span>
                <span class="author-block">Zizhuo Fu<sup>2</sup>,</span>
                <span class="author-block">Weike Wang<sup>1</sup>,</span>
                <span class="author-block">Xudong Tian<sup>1</sup>,</span>
                <span class="author-block">Anqi Lv<sup>1</sup>,</span>
                <span class="author-block">Laifu Man<sup>1</sup>,</span>
                <span class="author-block">Jianxiang Li<sup>1</sup>,</span>
                <span class="author-block">Feiyu Tao<sup>1</sup>,</span>
                <span class="author-block">Qihua Sun<sup>1</sup>,</span>
                <span class="author-block">Zhou Liang<sup>1</sup>,</span>
                <span class="author-block">Yushu Mu<sup>1</sup>,</span>
                <span class="author-block">Zhongxuan Li<sup>1</sup>,</span>
                <span class="author-block">Jing-Jun Zhang<sup>1</sup>,</span>
                <span class="author-block">Shutao Zhang<sup>1</sup>,</span>
                <span class="author-block">Xiaotian Li<sup>1</sup>,</span>
                <span class="author-block">Xingqi Xia<sup>1</sup>,</span>
                <span class="author-block">Jiawei Lin<sup>1</sup>,</span>
                <span class="author-block">Zheyu Shen<sup>1</sup>,</span>
                <span class="author-block">Jiahang Chen<sup>1</sup>,</span>
                <span class="author-block">Qiuhao Xiong<sup>1</sup>,</span>
                <span class="author-block">Binran Wang<sup>1</sup>,</span>
                <span class="author-block">Fengyuan Wang<sup>1</sup>,</span>
                <span class="author-block">Ziyang Ni<sup>1</sup>,</span>
                <span class="author-block">Bohan Zhang<sup>5</sup>,</span>
                <span class="author-block">Fan Cui<sup>4</sup>,</span>
                <span class="author-block">Changkun Shao<sup>1</sup>,</span>
                <span class="author-block"><a href="https://faculty.pku.edu.cn/caoqinghong/zh_CN/index.htm">Qing-Hong Cao</a><sup>1</sup>,</span>
                <span class="author-block"><a href="https://www.csrc.ac.cn/en/people/faculty/184.html">Ming-Xing Luo</a> <sup>3</sup>,</span>
                <span class="author-block"><a href="https://muhanzhang.github.io">Muhan Zhang</a><sup>2</sup>,</span>
                <span class="author-block"><a href="https://konformal.github.io">Hua Xing Zhu</a><sup>1</sup>,</span>
              
            </div>
            

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>School of Physics, Peking University</span><br>
              <span class="author-block"><sup>2</sup>Institute for Artificial Intelligence, Peking University</span><br>
              <span class="author-block"><sup>3</sup>Beijing Computational Science Research Center</span><br>
              <span class="author-block"><sup>4</sup>School of Integrated Circuits, Peking University</span><br>
              <span class="author-block"><sup>5</sup>Yuanpei College, Peking University</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2504.16074" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2504.16074" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/phybench-official" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://xxxxxxxxx" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="hero-body-image">
          <img src="./static/images/test_example.jpg" class="teaser-image" alt="Teaser image">
        </div>
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">PHYBench</span> is a benchmark for evaluating the physical reasoning capabilities of large
          language models.
        </h2>
      </div>
    </div>
  </section>

  
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">🌟 Overview</h2>
          <div class="content has-text-justified">
            <p><strong>PHYBench</strong> is the first large-scale benchmark specifically designed to evaluate <strong>physical perception</strong> and <strong>robust reasoning</strong> capabilities in Large Language Models (LLMs).</p>
            <p>With <strong>500 meticulously curated physics problems</strong> spanning mechanics, electromagnetism, thermodynamics, optics, modern physics, and advanced physics, it challenges models to demonstrate:</p>
            <ul>
              <li><strong>Real-world grounding</strong>: Problems based on tangible physical scenarios (e.g., ball inside a bowl, pendulum dynamics)</li>
              <li><strong>Multi-step reasoning</strong>: Average solution length of 3,000 characters requiring 10+ intermediate steps</li>
              <li><strong>Symbolic precision</strong>: Strict evaluation of LaTeX-formatted expressions through novel <strong>Expression Edit Distance (EED) Score</strong></li>
            </ul>
            <h3 class="title is-4">Key innovations:</h3>
            <ul>
              <li>🎯 <strong>EED Metric</strong>: Continuous scoring (0-100) measuring expression tree similarity, capturing partial correctness</li>
              <li>🏋️ <strong>Difficulty Spectrum</strong>: high school, undergraduate, Physics Olympiad-level problems</li>
              <li>🔍 <strong>Error Taxonomy</strong>: Explicit evaluation of Physical Perception (PP) vs Robust Reasoning (RR) failures</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </section>
  



  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">📚 Dataset Component</h2>
          <div class="content has-text-centered">
            <table class="table is-bordered is-striped is-fullwidth is-hoverable">
              <thead>
                <tr>
                  <th>Category</th>
                  <th>Subdomains</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Mechanics</td>
                  <td>Dynamics, Kinematics, Rotational</td>
                </tr>
                <tr>
                  <td>Electromagnetism</td>
                  <td>Fields, Circuits, Relativistic EM</td>
                </tr>
                <tr>
                  <td>Thermodynamics</td>
                  <td>Statistical Mechanics, Heat Engines</td>
                </tr>
                <tr>
                  <td>Optics</td>
                  <td>Wave, Geometric, Quantum Optics</td>
                </tr>
                <tr>
                  <td>Modern Physics</td>
                  <td>SR/GR, Quantum Mechanics</td>
                </tr>
                <tr>
                  <td>Advanced Physics</td>
                  <td>Plasma, Condensed Matter</td>
                </tr>
              </tbody>
            </table>
          </div>
  
          <h3 class="title is-4 has-text-left">Answer Types</h3>
          <div class="content has-text-left">
            <ul>
              <li> Strict symbolic expressions (e.g., <span>$\sqrt{\frac{2g}{3R}}$</span>)</li>
              <li> Multiple equivalent forms accepted</li>
              <li> No numerical approximations or equation chains</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="hero-body-image">
          <img src="./static/images/framework.jpg" class="teaser-image" alt="Teaser image">
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">🛠️ Data Curation</h2>
          <div class="content has-text-justified">
            <h3 class="title is-4">3-Stage Rigorous Validation Pipeline</h3>

            <h4>1. Expert Creation & Strict Screening</h4>
            <ul>
              <li><strong>178 PKU physics students</strong> contributed problems that are:
                <ul>
                  <li>Almost entirely original/custom-created</li>
                  <li>None easily found through direct internet searches or standard reference materials</li>
                </ul>
              </li>
              <li>Strict requirements:
                <ul>
                  <li>✅ Single unambiguous symbolic answer (e.g., <span>`T=2mg+4mv₀²/l`</span>)</li>
                  <li>✉️ Text-only solvability (no diagrams/multimodal inputs)</li>
                  <li>Rigorously precise statements to avoid ambiguity</li>
                  <li>Solvable using only basic physics principles (no complex specialized knowledge required)</li>
                </ul>
              </li>
              <li>No requirements on AI test to avoid filtering for AI weaknesses</li>
            </ul>

            <h4>2. Multi-Round Academic Review</h4>
            <p>Dedicated internal platform for peer review:</p>
            <img src="https://example.com/review-platform.png" alt="Review Interface">
            <p><strong>3-tier verification process:</strong></p>
            <ul>
              <li>Initial filtering: Reviewers assessed format validity and appropriateness (not filtering for AI weaknesses)</li>
              <li>Ambiguity detection and revision: Reviewers analyzed LLM-generated solutions to identify potential ambiguities in problem statements</li>
              <li>Iterative improvement cycle: Questions refined repeatedly until all LLMs can understand the question and follow the instructions to produce the expressions it believes to be right.</li>
            </ul>

            <h4>3. Human Expert Finalization</h4>
            <ul>
              <li><strong>81 PKU students participated:</strong></li>
              <li>Each student independently solved 8 problems from the dataset</li>
              <li>Evaluate question clarity, statement rigor, and answer correctness</li>
              <li>Establish of human baseline performance meanwhile</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">📊 Evaluation Protocol</h2>
          <div class="content has-text-justified">
            <h3 class="title is-4">Machine Evaluation</h3>
            <p><strong>Dual Metrics</strong>:</p>
            <ol>
              <li><strong>Accuracy</strong>: Binary correctness (expression equivalence via SymPy simplification)</li>
              <li><strong>EED Score</strong>: Continuous assessment of expression tree similarity</li>
            </ol>
            <p>The EED Score evaluates the similarity between the model-generated answer and the ground truth by leveraging the concept of expression tree edit distance. The process involves the following steps:</p>
            <ol>
              <li><strong>Simplification of Expressions</strong>: Both the ground truth (`gt`) and the model-generated answer (`gen`) are first converted into simplified symbolic expressions using the `sympy.simplify()` function. This step ensures that equivalent forms of the same expression are recognized as identical.</li>
              <li><strong>Equivalence Check</strong>: If the simplified expressions of `gt` and `gen` are identical, the EED Score is assigned a perfect score of 100, indicating complete correctness.</li>
              <li><strong>Tree Conversion and Edit Distance Calculation</strong>: If the expressions are not identical, they are converted into tree structures. The edit distance between these trees is then calculated using an extended version of the Zhang-Shasha algorithm. This distance represents the minimum number of node-level operations (insertions, deletions, and updates) required to transform one tree into the other.</li>
              <li><strong>Relative Edit Distance and Scoring</strong>: The relative edit distance \( r \) is computed as the ratio of the edit distance to the size of the ground truth tree. The EED Score is then determined based on this relative distance:
                <ul>
                  <li>If \( r = 0 \) (i.e., the expressions are identical), the score is 100.</li>
                  <li>If \( 0 < r < 0.6 \), the score is calculated as \( 60 - 100r \).</li>
                  <li>If \( r \geq 0.6 \), the score is 0, indicating a significant discrepancy between the model-generated answer and the ground truth.</li>
                </ul>
              </li>
            </ol>
            <p><strong>Key Advantages</strong>:</p>
            <ul>
              <li>204% higher sample efficiency vs binary metrics</li>
              <li>Distinguishes coefficient errors (EED=30-60) vs structural errors (EED<30)</li>
            </ul>

            <h3 class="title is-4">Human Baseline</h3>
            <ul>
              <li><strong>Participants</strong>: 81 PKU physics students</li>
              <li><strong>Protocol</strong>:
                <ul>
                  <li>8 problems per student: Each student solved a set of 8 problems from PHYBench dataset</li>
                  <li>Time-constrained solving: 3 hours.</li>
                </ul>
              </li>
              <li><strong>Performance metrics</strong>:
                <ul>
                  <li>61.9±2.1% average accuracy</li>
                  <li>70.4±1.8 average EED Score</li>
                  <li>Top quartile reached 71.4% accuracy and 80.4 EED Score</li>
                  <li>Significant outperformance vs LLMs: Human experts outperformed all evaluated LLMs at 99% confidence level</li>
                </ul>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">🚩 Citation</h2>
          <pre><code class="bibtex">
@article{
}
        </code></pre>
        </div>
      </div>
    </div>
  </section>
  
  

</body>

</html>